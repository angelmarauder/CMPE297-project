POST /v1/reasoning/completions
Host: api.openai.com
Authorization: Bearer <API_KEY>
Content-Type: application/json


Request:


{
  "model": "string",                       // e.g. "gpt-4-reasoner-v1"
  "prompt": [
    { "role": "system", "content": "…" },
    { "role": "user",   "content": "…" }
  ],
  "temperature": 0.0,                      // controls randomness
  "max_tokens": integer,
  "stop": [ "string", ... ],               // optional stop tokens
  "stream": boolean,                       // whether to stream partial output
  "trace": boolean,                        // whether to return reasoning trace
  "logit_bias": { "token_id": bias, ... }, // optional
  "functions": [ /* optional function schemas */ ],
  "user": "string"                         // optional user identifier
}
	

Notes / semantics:


* trace = true requests the model to include its internal reasoning steps (chain-of-thought or structured explanation) before the final answer.
* * If stream = true, responses may arrive incrementally (e.g. partial reasoning / partial answer).
* * functions may allow the model to call external tools during reasoning.
* * stop tokens signal where to cut responses.


















Non Streaming Response :


{
  "id": "string",
  "object": "completion",
  "model": "string",
  "created": timestamp,
  "choices": [
    {
      "message": {
        "role": "assistant",
        "content": "… final answer …",
        "trace": "… reasoning steps …"   // included if trace = true
      },
      "finish_reason": "stop" | "length" | "error"
    }
  ],
  "usage": {
    "prompt_tokens": integer,
    "completion_tokens": integer,
    "total_tokens": integer
  }
}